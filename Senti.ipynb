{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb6704-685f-43f9-b4eb-94d90a0218fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.special import softmax\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset_builder, load_dataset, get_dataset_split_names\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a314112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import notebook_login\n",
    "#notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f792d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_builder = load_dataset_builder(\"imdb\")\n",
    "\n",
    "# Inspect dataset features\n",
    "ds_builder.info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e185d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDb dataset from Hugging Face\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dataset split names\n",
    "get_dataset_split_names(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efadbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1f6d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = imdb['train']\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5802adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# check the distribution of the labels\n",
    "labels_train = pd.Series(ds_train['label'])\n",
    "ax = labels_train.value_counts().sort_index() \\\n",
    "    .plot(kind='bar',\n",
    "          title='Count of Reviews by Sentiment',\n",
    "          figsize=(10, 5))\n",
    "ax.set_xlabel('Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7f24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic NLTK preprocessing\n",
    "example_text = ds_train[0]['text']\n",
    "example_text\n",
    "tokens = nltk.word_tokenize(example_text)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER (Valence Aware Dictionary and Sentiment Reasoner), ignoring contexts\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8bdcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the polarity score on the entire training dataset\n",
    "results_train = {}\n",
    "counter = 0\n",
    "for row in tqdm(ds_train, total=len(ds_train)):\n",
    "    text = row['text']\n",
    "    results_train[counter] = sia.polarity_scores(text)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "vaders = pd.DataFrame(results_train).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
    "vaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeded193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(ds_train)\n",
    "df_train = df_train.reset_index().rename(columns={'index': 'Id'})\n",
    "vaders = vaders.merge(df_train, how='left')\n",
    "vaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot VADER scores by sentiment label\n",
    "ax = sns.barplot(data=vaders, x='label', y='compound')\n",
    "ax.set_title('Compound Score by Sentiment Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369de4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot VADER sub-scores by sentiment label\n",
    "fig, axs = plt.subplots(1, 3, figsize=(12, 3))\n",
    "sns.barplot(data=vaders, x='label', y='pos', ax=axs[0])\n",
    "sns.barplot(data=vaders, x='label', y='neu', ax=axs[1])\n",
    "sns.barplot(data=vaders, x='label', y='neg', ax=axs[2])\n",
    "axs[0].set_title('Positive')\n",
    "axs[1].set_title('Neutral')\n",
    "axs[2].set_title('Negative')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec69b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Roberta pretrained model for sentiment analysis\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the example text through the Roberta model and get the scores\n",
    "encoded_text = tokenizer(example_text, return_tensors='pt')\n",
    "output = model(**encoded_text)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores_dict = {\n",
    "    'roberta_neg' : scores[0],\n",
    "    'roberta_neu' : scores[1],\n",
    "    'roberta_pos' : scores[2]\n",
    "}\n",
    "scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dd7374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to run the Roberta model on each entry\n",
    "def polarity_scores_roberta(example):\n",
    "    # Tokenize with truncation\n",
    "    encoded_text = tokenizer(\n",
    "        example, \n",
    "        return_tensors='pt', \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=512\n",
    "    )\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    print(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg': scores[0],\n",
    "        'roberta_neu': scores[1],\n",
    "        'roberta_pos': scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function on the example text\n",
    "polarity_scores_roberta(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Roberta model on the training dataset\n",
    "results_train_both = {}\n",
    "counter = 0\n",
    "\n",
    "for row in tqdm(ds_train, total=len(ds_train)):\n",
    "    try:\n",
    "        text = row['text']\n",
    "        vader_result = sia.polarity_scores(text)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        both = {**vader_result_rename, **roberta_result}\n",
    "        results_train_both[counter] = both\n",
    "        counter += 1\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for row {counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to run the model on Mac GPUs\n",
    "\n",
    "#from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "# Check if MPS (Metal Performance Shaders) is available\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer and model\n",
    "model = model.to(device)\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(example_text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Get predictions\n",
    "predicted_class = torch.argmax(logits, dim=1).item()\n",
    "print(example_text)\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2249bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function to run the Roberta model on the GPUs\n",
    "def polarity_scores_roberta_gpu(example):\n",
    "    # Tokenize with truncation\n",
    "    encoded_text = tokenizer(\n",
    "        example, \n",
    "        return_tensors='pt', \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=512\n",
    "    ).to(device)\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_text)\n",
    "        #logits = outputs.logits\n",
    "\n",
    "    # Get predictions\n",
    "    scores = outputs[0][0].detach().cpu().numpy()\n",
    "    scores = softmax(scores)\n",
    "    #print(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg': scores[0],\n",
    "        'roberta_neu': scores[1],\n",
    "        'roberta_pos': scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af088ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function on the example text\n",
    "polarity_scores_roberta_gpu(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Roberta model on the training dataset using GPUs\n",
    "results_train_both = {}\n",
    "counter = 0\n",
    "\n",
    "for row in tqdm(ds_train, total=len(ds_train)):\n",
    "    try:\n",
    "        text = row['text']\n",
    "        vader_result = sia.polarity_scores(text)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "        roberta_result = polarity_scores_roberta_gpu(text)\n",
    "        both = {**vader_result_rename, **roberta_result}\n",
    "        results_train_both[counter] = both\n",
    "        counter += 1\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for row {counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0306ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Roberta model with batch input using GPUs\n",
    "def polarity_scores_roberta_gpu_batch(texts: List[str], batch_size: int = 256) -> Dict[int, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Analyze sentiment for a batch of texts.\n",
    "        \n",
    "    Args:\n",
    "        texts (List[str]): List of input texts\n",
    "        batch_size (int): Size of the batch to process\n",
    "            \n",
    "    Returns:\n",
    "        Dict[int, Dict[str, float]]: Dictionary of dictionaries containing sentiment probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    scores_dict = {}\n",
    "    num_batches = math.ceil(len(texts) / batch_size)\n",
    "         \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        # Get the batch of texts\n",
    "        batch_texts = texts[i*batch_size : (i+1)*batch_size]\n",
    "        \n",
    "        # Tokenize with truncation\n",
    "        encoded_text = tokenizer(\n",
    "                 batch_texts, \n",
    "                 return_tensors='pt', \n",
    "                 truncation=True, \n",
    "                 padding=True, \n",
    "                 max_length=512\n",
    "             ).to(device)\n",
    "             \n",
    "        # Run inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_text)\n",
    "            probabilities = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "             \n",
    "        # Get predictions\n",
    "        for j, probs in enumerate(probabilities.cpu().numpy()):\n",
    "            idx = i * batch_size + j\n",
    "            scores_dict[idx] = {\n",
    "                     \"roberta_neg\": float(probs[0]),\n",
    "                     \"roberta_neu\": float(probs[1]),\n",
    "                     \"roberta_pos\": float(probs[2])\n",
    "                 }\n",
    "         \n",
    "    return scores_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5739d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_batch_result = polarity_scores_roberta_gpu_batch(ds_train['text'])\n",
    "roberta_batch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e95f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4adfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ba75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_train_both).T\n",
    "results_df = results_df.reset_index().rename(columns={'index': 'Id'})\n",
    "results_df = results_df.merge(df_train, how='left')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbbd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the VADER and Roberta scores\n",
    "sns.pairplot(data=results_df,\n",
    "             vars=['vader_neg', 'vader_neu', 'vader_pos',\n",
    "                  'roberta_neg', 'roberta_neu', 'roberta_pos'],\n",
    "            hue='label',\n",
    "            palette='tab10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c390b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check the VADER and Roberta scores\n",
    "results_df.query('label == 0') \\\n",
    "    .sort_values('roberta_pos', ascending=False)['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc6ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.query('label == 0') \\\n",
    "    .sort_values('vader_pos', ascending=False)['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.query('label == 1') \\\n",
    "    .sort_values('roberta_neg', ascending=False)['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91dc112",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.query('label == 1') \\\n",
    "    .sort_values('vader_neg', ascending=False)['text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Transformers Pipeline for sentiment analysis\n",
    "from transformers import pipeline\n",
    "\n",
    "sent_pipeline = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004df64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pipeline(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pipeline('I love sentiment analysis!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pipeline('I hate having no gpus!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f06fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pipeline('What a beautiful day! All my clothes got wet!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a80604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a20803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the test set\n",
    "ds_test = imdb['test']\n",
    "ds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f93971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a validation set from the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d6676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
