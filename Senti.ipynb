{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ffb6704-685f-43f9-b4eb-94d90a0218fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/danc/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/danc/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/danc/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/danc/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/danc/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a314112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234a366e291f41d88b629c133ab4b066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f792d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['neg', 'pos'], id=None)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset_builder\n",
    "ds_builder = load_dataset_builder(\"imdb\")\n",
    "\n",
    "# Inspect dataset features\n",
    "ds_builder.info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e185d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDb dataset from Hugging Face\n",
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1073eeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'test', 'unsupervised']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dataset split names\n",
    "from datasets import get_dataset_split_names\n",
    "get_dataset_split_names(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efadbb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b1f6d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = imdb['train']\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5802adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# check the distribution of the labels\n",
    "labels_train = pd.Series(ds_train['label'])\n",
    "ax = labels_train.value_counts().sort_index() \\\n",
    "    .plot(kind='bar',\n",
    "          title='Count of Reviews by Sentiment',\n",
    "          figsize=(10, 5))\n",
    "ax.set_xlabel('Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb7f24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic NLTK preprocessing\n",
    "example_text = ds_train[0]['text']\n",
    "example_text\n",
    "tokens = nltk.word_tokenize(example_text)\n",
    "tagged = nltk.pos_tag(tokens)\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15fd8e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.04, 'neu': 0.922, 'pos': 0.038, 'compound': -0.1167}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VADER (Valence Aware Dictionary and Sentiment Reasoner), ignoring contexts\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff8bdcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ac7e42b13b4818b259cbca39200e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the polarity score on the entire training dataset\n",
    "results_train = {}\n",
    "counter = 0\n",
    "for row in tqdm(ds_train, total=len(ds_train)):\n",
    "    text = row['text']\n",
    "    results_train[counter] = sia.polarity_scores(text)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6492a603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.8648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.8324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.0924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.9358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.6056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.9799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.9909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id    neg    neu    pos  compound\n",
       "0          0  0.040  0.922  0.038   -0.1167\n",
       "1          1  0.085  0.869  0.046   -0.8648\n",
       "2          2  0.068  0.798  0.133    0.8324\n",
       "3          3  0.127  0.749  0.124   -0.0924\n",
       "4          4  0.083  0.876  0.041   -0.9358\n",
       "...      ...    ...    ...    ...       ...\n",
       "24995  24995  0.098  0.716  0.186    0.9136\n",
       "24996  24996  0.116  0.744  0.140    0.6056\n",
       "24997  24997  0.072  0.684  0.244    0.9799\n",
       "24998  24998  0.075  0.803  0.122    0.9909\n",
       "24999  24999  0.049  0.795  0.155    0.7701\n",
       "\n",
       "[25000 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vaders = pd.DataFrame(results_train).T\n",
    "vaders = vaders.reset_index().rename(columns={'index': 'Id'})\n",
    "vaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeded193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.1167</td>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.8648</td>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-0.0924</td>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.9358</td>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>24995</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.9136</td>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>24996</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.6056</td>\n",
       "      <td>I love this movie like no other. Another time ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>24997</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>24998</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.9909</td>\n",
       "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>24999</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.7701</td>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id    neg    neu    pos  compound  \\\n",
       "0          0  0.040  0.922  0.038   -0.1167   \n",
       "1          1  0.085  0.869  0.046   -0.8648   \n",
       "2          2  0.068  0.798  0.133    0.8324   \n",
       "3          3  0.127  0.749  0.124   -0.0924   \n",
       "4          4  0.083  0.876  0.041   -0.9358   \n",
       "...      ...    ...    ...    ...       ...   \n",
       "24995  24995  0.098  0.716  0.186    0.9136   \n",
       "24996  24996  0.116  0.744  0.140    0.6056   \n",
       "24997  24997  0.072  0.684  0.244    0.9799   \n",
       "24998  24998  0.075  0.803  0.122    0.9909   \n",
       "24999  24999  0.049  0.795  0.155    0.7701   \n",
       "\n",
       "                                                    text  label  \n",
       "0      I rented I AM CURIOUS-YELLOW from my video sto...      0  \n",
       "1      \"I Am Curious: Yellow\" is a risible and preten...      0  \n",
       "2      If only to avoid making this type of film in t...      0  \n",
       "3      This film was probably inspired by Godard's Ma...      0  \n",
       "4      Oh, brother...after hearing about this ridicul...      0  \n",
       "...                                                  ...    ...  \n",
       "24995  A hit at the time but now better categorised a...      1  \n",
       "24996  I love this movie like no other. Another time ...      1  \n",
       "24997  This film and it's sequel Barry Mckenzie holds...      1  \n",
       "24998  'The Adventures Of Barry McKenzie' started lif...      1  \n",
       "24999  The story centers around Barry McKenzie who mu...      1  \n",
       "\n",
       "[25000 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(ds_train)\n",
    "df_train = df_train.reset_index().rename(columns={'index': 'Id'})\n",
    "vaders = vaders.merge(df_train, how='left')\n",
    "vaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec69b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1f356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the test set\n",
    "ds_test = imdb['test']\n",
    "ds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f93971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a validation set from the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d6676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
